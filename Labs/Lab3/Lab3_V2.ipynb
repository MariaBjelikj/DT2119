{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Lab3.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/bjelikj/DT2119/blob/master/Labs/Lab3/Lab3_V2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_300NuWNwpuZ",
        "colab_type": "code",
        "outputId": "5aa77b2b-07bc-4bf9-c6df-8ae5b54717d7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 340
        }
      },
      "source": [
        "import os\n",
        "from google.colab import drive\n",
        "\n",
        "ROOT = '/content/drive'\n",
        "PROJ = 'My Drive/DT2119_Lab3'\n",
        "PROJECT_PATH = os.path.join(ROOT, PROJ)\n",
        "!mkdir '{PROJECT_PATH}'\n",
        "drive.mount(ROOT)\n",
        "\n",
        "GIT_REPOSITORY = \"DT2119/Labs/Lab3\"\n",
        "GIT_PATH = \"https://github.com/bjelikj/DT2119.git\"\n",
        "GIT_SUBFOLDER = 'DT2119/Labs/Lab3'\n",
        "\n",
        "print('Directory where project will be stored: ', PROJECT_PATH)\n",
        "\n",
        "print(\"Creating temp directory and cloning...\")\n",
        "%cd '{PROJECT_PATH}'\n",
        "!mkdir ./temp\n",
        "%cd 'temp'\n",
        "%pwd\n",
        "!git clone \"{GIT_PATH}\"\n",
        "!ls\n",
        "print(\"Moving files to Drive...\")\n",
        "%cd '{PROJECT_PATH}'\n",
        "!mv ./temp/* \"{PROJECT_PATH}\"\n",
        "print(\"Removing temp directory...\")\n",
        "%cd '{PROJECT_PATH}'\n",
        "!rm -r ./temp\n",
        "# !rsync -aP --exclude=data/ \"{PROJECT_PATH}\"/*  ./\n",
        "!rsync -aP \"{PROJECT_PATH}\"/*  ./"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "mkdir: cannot create directory ‘/content/drive/My Drive/DT2119_Lab3’: File exists\n",
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "Directory where project will be stored:  /content/drive/My Drive/DT2119_Lab3\n",
            "Creating temp directory and cloning...\n",
            "/content/drive/My Drive/DT2119_Lab3\n",
            "/content/drive/My Drive/DT2119_Lab3/temp\n",
            "Cloning into 'DT2119'...\n",
            "remote: Enumerating objects: 128, done.\u001b[K\n",
            "remote: Counting objects: 100% (128/128), done.\u001b[K\n",
            "remote: Compressing objects: 100% (93/93), done.\u001b[K\n",
            "remote: Total 216 (delta 64), reused 82 (delta 30), pack-reused 88\u001b[K\n",
            "Receiving objects: 100% (216/216), 53.24 MiB | 14.80 MiB/s, done.\n",
            "Resolving deltas: 100% (106/106), done.\n",
            "DT2119\n",
            "Moving files to Drive...\n",
            "/content/drive/My Drive/DT2119_Lab3\n",
            "Removing temp directory...\n",
            "/content/drive/My Drive/DT2119_Lab3\n",
            "sending incremental file list\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KvAJEe5uPJ69",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "691da966-d978-49d2-b281-08f76afcda3f"
      },
      "source": [
        "WORKING_SUBFOLDER = os.path.join(PROJECT_PATH, GIT_SUBFOLDER)\n",
        "print(WORKING_SUBFOLDER)\n",
        "%cd '{WORKING_SUBFOLDER}'\n",
        "!git pull"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/My Drive/DT2119_Lab3/DT2119/Labs/Lab3\n",
            "/content/drive/My Drive/DT2119_Lab3/DT2119/Labs/Lab3\n",
            "Already up to date.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oP6t6vObxeDP",
        "colab_type": "code",
        "outputId": "e0035f4c-2044-498e-a1bf-ae13c7a30a72",
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 425
        }
      },
      "source": [
        "\"\"\"\n",
        "Necessary files:\n",
        "- lab3_proto.py\n",
        "- lab3_tools.py\n",
        "- lab1_proto.py\n",
        "- lab1_tools.py\n",
        "- prondict.py\n",
        "\n",
        "If not uploaded to Google Drive:\n",
        "- lab2_models_all.npz\n",
        "- lab3_example.npz\n",
        "\"\"\"\n",
        "\"\"\"\n",
        "if IN_COLAB:\n",
        "    !rm lab1_proto.py\n",
        "    !rm lab1_tools.py\n",
        "    !rm lab2_proto.py\n",
        "    !rm lab2_tools.py\n",
        "    !rm lab3_proto.py\n",
        "    !rm lab3_tools.py\n",
        "    !rm lab3_example.npz\n",
        "    !rm lab2_models_all.npz\n",
        "    !ls\n",
        "\"\"\"\n",
        "from google.colab import files\n",
        "files.upload()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-b7ea8a61-f3b2-44f6-8aff-70ed8b3e0eef\" name=\"files[]\" multiple disabled />\n",
              "     <output id=\"result-b7ea8a61-f3b2-44f6-8aff-70ed8b3e0eef\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Saving lab1_proto.py to lab1_proto.py\n",
            "Saving lab1_tools.py to lab1_tools.py\n",
            "Saving lab2_proto.py to lab2_proto.py\n",
            "Saving lab2_tools.py to lab2_tools.py\n",
            "Saving lab3_proto.py to lab3_proto.py\n",
            "Saving lab3_tools.py to lab3_tools.py\n",
            "Saving prondict.py to prondict.py\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'lab1_proto.py': b'# DT2119, Lab 1 Feature Extraction\\r\\nimport numpy as np\\r\\nimport matplotlib.pyplot as plt\\r\\nimport scipy.signal as ssi\\r\\nfrom scipy import fftpack\\r\\nfrom lab1_tools import trfbank\\r\\nfrom scipy.fftpack.realtransforms import dct\\r\\nfrom lab1_tools import *\\r\\nfrom scipy.spatial.distance import euclidean\\r\\nfrom scipy.spatial.distance import cdist\\r\\n\\r\\n# Function given by the exercise ----------------------------------\\r\\n\\r\\ndef mspec(samples, winlen=400, winshift=200, preempcoeff=0.97, nfft=512, samplingrate=20000):\\r\\n    \"\"\"Computes Mel Filterbank features.\\r\\n\\r\\n    Args:\\r\\n        samples: array of speech samples with shape (N,)\\r\\n        winlen: lenght of the analysis window\\r\\n        winshift: number of samples to shift the analysis window at every time step\\r\\n        preempcoeff: pre-emphasis coefficient\\r\\n        nfft: length of the Fast Fourier Transform (power of 2, >= winlen)\\r\\n        samplingrate: sampling rate of the original signal\\r\\n\\r\\n    Returns:\\r\\n        N x nfilters array with mel filterbank features (see trfbank for nfilters)\\r\\n    \"\"\"\\r\\n    frames = enframe(samples, winlen, winshift)\\r\\n    preemph = preemp(frames, preempcoeff)\\r\\n    windowed = windowing(preemph)\\r\\n    spec = powerSpectrum(windowed, nfft)\\r\\n    return logMelSpectrum(spec, samplingrate)\\r\\n\\r\\ndef mfcc(samples, winlen = 400, winshift = 200, preempcoeff=0.97, nfft=512, nceps=13, samplingrate=20000, liftercoeff=22):\\r\\n    \"\"\"Computes Mel Frequency Cepstrum Coefficients.\\r\\n\\r\\n    Args:\\r\\n        samples: array of speech samples with shape (N,)\\r\\n        winlen: lenght of the analysis window\\r\\n        winshift: number of samples to shift the analysis window at every time step\\r\\n        preempcoeff: pre-emphasis coefficient\\r\\n        nfft: length of the Fast Fourier Transform (power of 2, >= winlen)\\r\\n        nceps: number of cepstrum coefficients to compute\\r\\n        samplingrate: sampling rate of the original signal\\r\\n        liftercoeff: liftering coefficient used to equalise scale of MFCCs\\r\\n\\r\\n    Returns:\\r\\n        N x nceps array with lifetered MFCC coefficients\\r\\n    \"\"\"\\r\\n    mspecs = mspec(samples, winlen, winshift, preempcoeff, nfft, samplingrate)\\r\\n    ceps = cepstrum(mspecs, nceps)\\r\\n    return lifter(ceps, liftercoeff)\\r\\n\\r\\n# Functions to be implemented ----------------------------------\\r\\n\\r\\ndef enframe(samples, winlen, winshift):\\r\\n    \"\"\"\\r\\n    Slices the input samples into overlapping windows.\\r\\n\\r\\n    Args:\\r\\n        winlen: window length in samples.\\r\\n        winshift: shift of consecutive windows in samples\\r\\n    Returns:\\r\\n        numpy array [N x winlen], where N is the number of windows that fit\\r\\n        in the input signal\\r\\n    \"\"\"\\r\\n    \\r\\n    frames = np.array(samples[0:winlen]) # Start array here with the first frame\\r\\n                                         # and stack all the frames on top for \\r\\n                                         # each window shift\\r\\n    for i in range(winshift, len(samples) - winlen, winshift): \\r\\n        frames = np.vstack([frames, samples[i:i+winlen]]) # extract and stack frames\\r\\n        \\r\\n    return frames\\r\\n    \\r\\n    \\r\\ndef preemp(input, p=0.97):\\r\\n    \"\"\"\\r\\n    Pre-emphasis filter.\\r\\n\\r\\n    Args:\\r\\n        input: array of speech frames [N x M] where N is the number of frames and\\r\\n               M the samples per frame\\r\\n        p: preemhasis factor (defaults to the value specified in the exercise)\\r\\n\\r\\n    Output:\\r\\n        output: array of pre-emphasised speech samples\\r\\n    Note (you can use the function lfilter from scipy.signal)\\r\\n    \"\"\"\\r\\n    \\r\\n    # For the definition of the filter coefficients, check the documentation at\\r\\n    # https://docs.scipy.org/doc/scipy/reference/generated/scipy.signal.lfilter.html\\r\\n    # and slide 67 in lecture 02 (alpha = p = 0.97)\\r\\n    return ssi.lfilter([1, -p], [1], input)\\r\\n\\r\\n\\r\\ndef windowing(input):\\r\\n    \"\"\"\\r\\n    Applies hamming window to the input frames.\\r\\n\\r\\n    Args:\\r\\n        input: array of speech samples [N x M] where N is the number of frames and\\r\\n               M the samples per frame\\r\\n    Output:\\r\\n        array of windoed speech samples [N x M]\\r\\n    Note (you can use the function hamming from scipy.signal, include the sym=0 option\\r\\n    if you want to get the same results as in the example)\\r\\n    \"\"\"\\r\\n    \\r\\n    hamming_window = ssi.hamming(input.shape[1], sym=False)\\r\\n    \\r\\n    # Why we use hamming window at: \\r\\n    # https://stackoverflow.com/questions/5418951/what-is-the-hamming-window-for\\r\\n    return hamming_window * input\\r\\n\\r\\n\\r\\ndef powerSpectrum(input, nfft):\\r\\n    \"\"\"\\r\\n    Calculates the power spectrum of the input signal, that is the square of the modulus of the FFT\\r\\n\\r\\n    Args:\\r\\n        input: array of speech samples [N x M] where N is the number of frames and\\r\\n               M the samples per frame\\r\\n        nfft: length of the FFT\\r\\n    Output:\\r\\n        array of power spectra [N x nfft]\\r\\n    Note: you can use the function fft from scipy.fftpack\\r\\n    \"\"\"\\r\\n    \\r\\n    return np.power(np.abs(fftpack.fft(input, nfft)), 2)\\r\\n\\r\\ndef logMelSpectrum(input, samplingrate):\\r\\n    \"\"\"\\r\\n    Calculates the log output of a Mel filterbank when the input is the power spectrum\\r\\n\\r\\n    Args:\\r\\n        input: array of power spectrum coefficients [N x nfft] where N is the number of frames and\\r\\n               nfft the length of each spectrum\\r\\n        samplingrate: sampling rate of the original signal (used to calculate the filterbank shapes)\\r\\n    Output:\\r\\n        array of Mel filterbank log outputs [N x nmelfilters] where nmelfilters is the number\\r\\n        of filters in the filterbank\\r\\n    Note: use the trfbank function provided in lab1_tools.py to calculate the filterbank shapes and\\r\\n          nmelfilters\\r\\n    \"\"\"\\r\\n    \\r\\n    return np.log(input.dot(trfbank(samplingrate, input.shape[1]).T))\\r\\n\\r\\n\\r\\ndef cepstrum(input, nceps):\\r\\n    \"\"\"\\r\\n    Calulates Cepstral coefficients from mel spectrum applying Discrete Cosine Transform\\r\\n\\r\\n    Args:\\r\\n        input: array of log outputs of Mel scale filterbank [N x nmelfilters] where N is the\\r\\n               number of frames and nmelfilters the length of the filterbank\\r\\n        nceps: number of output cepstral coefficients\\r\\n    Output:\\r\\n        array of Cepstral coefficients [N x nceps]\\r\\n    Note: you can use the function dct from scipy.fftpack.realtransforms\\r\\n    \"\"\"\\r\\n\\r\\n    return dct(input)[:, :nceps]\\r\\n    \\r\\ndef dtw(x, y, dist, Comp_Dist = False):\\r\\n    \"\"\"Dynamic Time Warping.\\r\\n\\r\\n    Args:\\r\\n        x, y: arrays of size NxD and MxD respectively, where D is the dimensionality\\r\\n              and N, M are the respective lenghts of the sequences\\r\\n        dist: distance function (can be used in the code as dist(x[i], y[j]))\\r\\n\\r\\n    Outputs:\\r\\n        d: global distance between the sequences (scalar) normalized to len(x)+len(y)\\r\\n        LD: local distance between frames from x and y (NxM matrix)\\r\\n        AD: accumulated distance between frames of x and y (NxM matrix)\\r\\n        path: best path through AD\\r\\n\\r\\n    Note that you only need to define the first output for this exercise.\\r\\n    \"\"\"\\r\\n\\r\\n    LD = np.zeros((x.shape[0],y.shape[0]))\\r\\n    # LD = cdist(x,y,metric=\\'euclidean\\')\\r\\n    AD = np.copy(LD)\\r\\n    H, K = AD.shape\\r\\n    path = []\\r\\n    idx_arr = [[1, 0], [1, 1], [0, 1]]\\r\\n    prev_idx = np.zeros((2, H, K), dtype=int)\\r\\n    h_path = H - 1\\r\\n    k_path = K - 1\\r\\n    \\r\\n    for h in range(H):\\r\\n        for k in range(K):\\r\\n            LD[h, k] = dist(x[h],y[k])\\r\\n            prev_dist = [AD[h-1, k], AD[h-1, k-1], AD[h, k-1]]\\r\\n            prev_idx[:, h, k] = idx_arr[np.argmin(prev_dist)]\\r\\n            AD[h][k] = LD[h][k] + min(prev_dist)\\r\\n\\r\\n    d = AD[-1][-1]\\r\\n\\r\\n    if Comp_Dist:\\r\\n        return d\\r\\n\\r\\n    while (h_path>=0 and k_path>=0):\\r\\n        path.append([h_path, k_path])\\r\\n        h_path, k_path = np.array([h_path,k_path]) - prev_idx[:, h_path, k_path]\\r\\n\\r\\n    return d, LD, AD, np.asarray(path)\\r\\n\\r\\ndef compare(frames, example_frames):\\r\\n    \"\"\" Returns True if frames and example_frame are equal \"\"\"\\r\\n    \\r\\n    return np.isclose(frames, example_frames).all()\\r\\n\\r\\ndef getEuclidean(x, y):\\r\\n        return euclidean(x,y)\\r\\n',\n",
              " 'lab1_tools.py': b'import numpy as np\\r\\n# DT2119, Lab 1 Feature Extraction\\r\\n# - Functions given by the exercise -------------------------------------------- \\r\\n\\r\\ndef tidigit2labels(tidigitsarray):\\r\\n    \"\"\"\\r\\n    Return a list of labels including gender, speaker, digit and repetition information for each\\r\\n    utterance in tidigitsarray. Useful for plots.\\r\\n    \"\"\"\\r\\n    labels = []\\r\\n    nex = len(tidigitsarray)\\r\\n    for ex in range(nex):\\r\\n        labels.append(tidigitsarray[ex][\\'gender\\'] + \\'_\\' + \\r\\n                      tidigitsarray[ex][\\'speaker\\'] + \\'_\\' + \\r\\n                      tidigitsarray[ex][\\'digit\\'] + \\'_\\' + \\r\\n                      tidigitsarray[ex][\\'repetition\\'])\\r\\n    return labels\\r\\n\\r\\ndef dither(samples, level=1.0):\\r\\n    \"\"\"\\r\\n    Applies dithering to the samples. Adds Gaussian noise to the samples to avoid numerical\\r\\n        errors in the subsequent FFT calculations.\\r\\n\\r\\n        samples: array of speech samples\\r\\n        level: decides the amount of dithering (see code for details)\\r\\n\\r\\n    Returns:\\r\\n        array of dithered samples (same shape as samples)\\r\\n    \"\"\"\\r\\n    return samples + level*np.random.normal(0,1, samples.shape)\\r\\n    \\r\\n\\r\\ndef lifter(mfcc, lifter=22):\\r\\n    \"\"\"\\r\\n    Applies liftering to improve the relative range of MFCC coefficients.\\r\\n\\r\\n       mfcc: NxM matrix where N is the number of frames and M the number of MFCC coefficients\\r\\n       lifter: lifering coefficient\\r\\n\\r\\n    Returns:\\r\\n       NxM array with lifeterd coefficients\\r\\n    \"\"\"\\r\\n    nframes, nceps = mfcc.shape\\r\\n    cepwin = 1.0 + lifter/2.0 * np.sin(np.pi * np.arange(nceps) / lifter)\\r\\n    return np.multiply(mfcc, np.tile(cepwin, nframes).reshape((nframes,nceps)))\\r\\n\\r\\ndef hz2mel(f):\\r\\n    \"\"\"Convert an array of frequency in Hz into mel.\"\"\"\\r\\n    return 1127.01048 * np.log(f/700 +1)\\r\\n\\r\\ndef trfbank(fs, nfft, lowfreq=133.33, linsc=200/3., logsc=1.0711703, nlinfilt=13, nlogfilt=27, equalareas=False):\\r\\n    \"\"\"Compute triangular filterbank for MFCC computation.\\r\\n\\r\\n    Inputs:\\r\\n    fs:         sampling frequency (rate)\\r\\n    nfft:       length of the fft\\r\\n    lowfreq:    frequency of the lowest filter\\r\\n    linsc:      scale for the linear filters\\r\\n    logsc:      scale for the logaritmic filters\\r\\n    nlinfilt:   number of linear filters\\r\\n    nlogfilt:   number of log filters\\r\\n\\r\\n    Outputs:\\r\\n    res:  array with shape [N, nfft], with filter amplitudes for each column.\\r\\n            (N=nlinfilt+nlogfilt)\\r\\n    From scikits.talkbox\"\"\"\\r\\n    # Total number of filters\\r\\n    nfilt = nlinfilt + nlogfilt\\r\\n\\r\\n    #------------------------\\r\\n    # Compute the filter bank\\r\\n    #------------------------\\r\\n    # Compute start/middle/end points of the triangular filters in spectral\\r\\n    # domain\\r\\n    freqs = np.zeros(nfilt+2)\\r\\n    freqs[:nlinfilt] = lowfreq + np.arange(nlinfilt) * linsc\\r\\n    freqs[nlinfilt:] = freqs[nlinfilt-1] * logsc ** np.arange(1, nlogfilt + 3)\\r\\n    if equalareas:\\r\\n        heights = np.ones(nfilt)\\r\\n    else:\\r\\n        heights = 2./(freqs[2:] - freqs[0:-2])\\r\\n\\r\\n    # Compute filterbank coeff (in fft domain, in bins)\\r\\n    fbank = np.zeros((nfilt, nfft))\\r\\n    # FFT bins (in Hz)\\r\\n    nfreqs = np.arange(nfft) / (1. * nfft) * fs\\r\\n    for i in range(nfilt):\\r\\n        low = freqs[i]\\r\\n        cen = freqs[i+1]\\r\\n        hi = freqs[i+2]\\r\\n\\r\\n        lid = np.arange(np.floor(low * nfft / fs) + 1,\\r\\n                        np.floor(cen * nfft / fs) + 1, dtype=np.int)\\r\\n        lslope = heights[i] / (cen - low)\\r\\n        rid = np.arange(np.floor(cen * nfft / fs) + 1,\\r\\n                        np.floor(hi * nfft / fs) + 1, dtype=np.int)\\r\\n        rslope = heights[i] / (hi - cen)\\r\\n        fbank[i][lid] = lslope * (nfreqs[lid] - low)\\r\\n        fbank[i][rid] = rslope * (hi - nfreqs[rid])\\r\\n\\r\\n    return fbank\\r\\n',\n",
              " 'lab2_proto.py': b'import numpy as np\\r\\nfrom lab2_tools import *\\r\\n\\r\\ndef concatTwoHMMs(hmm1, hmm2):\\r\\n    \"\"\" Concatenates 2 HMM models\\r\\n\\r\\n    Args:\\r\\n       hmm1, hmm2: two dictionaries with the following keys:\\r\\n           name: phonetic or word symbol corresponding to the model\\r\\n           startprob: M+1 array with priori probability of state\\r\\n           transmat: (M+1)x(M+1) transition matrix\\r\\n           means: MxD array of mean vectors\\r\\n           covars: MxD array of variances\\r\\n\\r\\n    D is the dimension of the feature vectors\\r\\n    M is the number of emitting states in each HMM model (could be different for each)\\r\\n\\r\\n    Output\\r\\n       dictionary with the same keys as the input but concatenated models:\\r\\n          startprob: K+1 array with priori probability of state\\r\\n          transmat: (K+1)x(K+1) transition matrix\\r\\n             means: KxD array of mean vectors\\r\\n            covars: KxD array of variances\\r\\n\\r\\n    K is the sum of the number of emitting states from the input models\\r\\n   \\r\\n    Example:\\r\\n       twoHMMs = concatHMMs(phoneHMMs[\\'sil\\'], phoneHMMs[\\'ow\\'])\\r\\n\\r\\n    See also: the concatenating_hmms.pdf document in the lab package\\r\\n    \"\"\"\\r\\n    HMMs = {}\\r\\n    HMMs[\\'name\\'] = hmm1[\\'name\\'] + hmm2[\\'name\\']\\r\\n\\r\\n    # Concatenate start probabilities\\r\\n    HMMs[\\'startprob\\'] = np.hstack((hmm1[\\'startprob\\'][0:-1], np.multiply(hmm1[\\'startprob\\'][-1], hmm2[\\'startprob\\'])))\\r\\n    \\r\\n    # Concatenate transition matrices\\r\\n    temp1 = np.hstack((hmm1[\\'transmat\\'][0:-1, 0:-1], hmm1[\\'transmat\\'][0:-1, -1][np.newaxis].T.dot(hmm2[\\'startprob\\'][np.newaxis])))\\r\\n    temp2 = np.hstack((np.zeros((hmm2[\\'transmat\\'].shape[0], hmm1[\\'transmat\\'].shape[1] - 1)), hmm2[\\'transmat\\']))\\r\\n    HMMs[\\'transmat\\'] = np.vstack((temp1, temp2))\\r\\n    HMMs[\\'transmat\\'] = np.vstack((temp1, temp2))\\r\\n    \\r\\n    \\r\\n    # Concatenate means\\r\\n    HMMs[\\'means\\'] = np.vstack((hmm1[\\'means\\'], hmm2[\\'means\\']))\\r\\n    \\r\\n    # Concatenate covariances\\r\\n    HMMs[\\'covars\\'] = np.vstack((hmm1[\\'covars\\'], hmm2[\\'covars\\']))\\r\\n    \\r\\n    return HMMs\\r\\n\\r\\n\\r\\n# this is already implemented, but based on concat2HMMs() above\\r\\ndef concatHMMs(hmmmodels, namelist):\\r\\n    \"\"\" Concatenates HMM models in a left to right manner\\r\\n\\r\\n    Args:\\r\\n       hmmmodels: dictionary of models indexed by model name. \\r\\n       hmmmodels[name] is a dictionaries with the following keys:\\r\\n           name: phonetic or word symbol corresponding to the model\\r\\n           startprob: M+1 array with priori probability of state\\r\\n           transmat: (M+1)x(M+1) transition matrix\\r\\n           means: MxD array of mean vectors\\r\\n           covars: MxD array of variances\\r\\n       namelist: list of model names that we want to concatenate\\r\\n\\r\\n    D is the dimension of the feature vectors\\r\\n    M is the number of emitting states in each HMM model (could be\\r\\n      different in each model)\\r\\n\\r\\n    Output\\r\\n       combinedhmm: dictionary with the same keys as the input but\\r\\n                    combined models:\\r\\n         startprob: K+1 array with priori probability of state\\r\\n          transmat: (K+1)x(K+1) transition matrix\\r\\n             means: KxD array of mean vectors\\r\\n            covars: KxD array of variances\\r\\n\\r\\n    K is the sum of the number of emitting states from the input models\\r\\n\\r\\n    Example:\\r\\n       wordHMMs[\\'o\\'] = concatHMMs(phoneHMMs, [\\'sil\\', \\'ow\\', \\'sil\\'])\\r\\n    \"\"\"\\r\\n    concat = hmmmodels[namelist[0]]\\r\\n    for idx in range(1, len(namelist)):\\r\\n        concat = concatTwoHMMs(concat, hmmmodels[namelist[idx]])\\r\\n    return concat\\r\\n\\r\\n\\r\\ndef gmmloglik(log_emlik, weights):\\r\\n    \"\"\"Log Likelihood for a GMM model based on Multivariate Normal Distribution.\\r\\n\\r\\n    Args:\\r\\n        log_emlik: array like, shape (N, K).\\r\\n            contains the log likelihoods for each of N observations and\\r\\n            each of K distributions\\r\\n        weights:   weight vector for the K components in the mixture\\r\\n\\r\\n    Output:\\r\\n        gmmloglik: scalar, log likelihood of data given the GMM model.\\r\\n    \"\"\"\\r\\n    log_lik_gmm = 0\\r\\n    for obs in range(len(log_emlik)):\\r\\n        log_lik_gmm += logsumexp(log_emlik[obs, :] + np.log(weights))\\r\\n    return log_lik_gmm  \\r\\n    \\r\\n\\r\\ndef forward(log_emlik, log_startprob, log_transmat):\\r\\n    \"\"\"Forward (alpha) probabilities in log domain.\\r\\n\\r\\n    Args:\\r\\n        log_emlik: NxM array of emission log likelihoods, N frames, M states\\r\\n        log_startprob: log probability to start in state i\\r\\n        log_transmat: log transition probability from state i to j\\r\\n\\r\\n    Output:\\r\\n        forward_prob: NxM array of forward log probabilities for each of the M states in the model\\r\\n    \"\"\"\\r\\n    N, M = log_emlik.shape\\r\\n    forward_prob = np.zeros(log_emlik.shape)\\r\\n\\r\\n    forward_prob[0, :] = log_startprob[:-1] + log_emlik[0, :]\\r\\n\\r\\n    for n in range(1, N):\\r\\n        for j in range(M):\\r\\n            forward_prob[n, j] = logsumexp(forward_prob[n-1, :] + log_transmat[:-1, j]) + log_emlik[n, j]\\r\\n\\r\\n    return forward_prob\\r\\n\\r\\n\\r\\ndef backward(log_emlik, log_startprob, log_transmat):\\r\\n    \"\"\"Backward (beta) probabilities in log domain.\\r\\n\\r\\n    Args:\\r\\n        log_emlik: NxM array of emission log likelihoods, N frames, M states\\r\\n        log_startprob: log probability to start in state i\\r\\n        log_transmat: transition log probability from state i to j\\r\\n\\r\\n    Output:\\r\\n        backward_prob: NxM array of backward log probabilities for each of the M states in the model\\r\\n    \"\"\"\\r\\n    N, M = log_emlik.shape\\r\\n\\r\\n    backward_prob = np.zeros([N,M])\\r\\n\\r\\n    for i in reversed(range(N - 1)):\\r\\n        for j in range(M):\\r\\n            backward_prob[i,j] = logsumexp(log_transmat[j,:-1] + log_emlik[i+1,:] + backward_prob[i+1,:])\\r\\n\\r\\n    return backward_prob\\r\\n    \\r\\n\\r\\ndef viterbi(log_emlik, log_startprob, log_transmat, forceFinalState=True):\\r\\n    \"\"\"Viterbi path.\\r\\n\\r\\n    Args:\\r\\n        log_emlik: NxM array of emission log likelihoods, N frames, M states\\r\\n        log_startprob: log probability to start in state i\\r\\n        log_transmat: transition log probability from state i to j\\r\\n        forceFinalState: if True, start backtracking from the final state in\\r\\n                  the model, instead of the best state at the last time step\\r\\n\\r\\n    Output:\\r\\n        viterbi_loglik: log likelihood of the best path\\r\\n        viterbi_path: best path\\r\\n    \"\"\"\\r\\n    N, M = log_emlik.shape\\r\\n    \\r\\n    V = np.zeros([N, M])\\r\\n    B = np.zeros([N, M])\\r\\n\\r\\n    # Initialization\\r\\n    V[0, :] = log_startprob[:-1] + log_emlik[0, :] # Viterbi log likelihoods\\r\\n    B[0, :] = 0 # Viterbi indices\\r\\n\\r\\n    # Induction - propagating best paths forwards\\r\\n    for i in range(1, N): # i = observation\\r\\n        for j in range(M): # j = state \\r\\n            V[i][j] = np.max(V[i-1, :] + log_transmat[:-1, j]) + log_emlik[i][j]\\r\\n            B[i][j] = np.argmax(V[i-1, :] + log_transmat[:-1, j])\\r\\n\\r\\n    viterbi_loglik = np.max(V[-1, :])\\r\\n\\r\\n    # Backtracking \\r\\n    viterbi_path = np.zeros(N) # best path\\r\\n    viterbi_path[-1] = np.argmax(B[-1, :]) # start from last state\\r\\n    for i in reversed(range(N - 1)):\\r\\n        viterbi_path[i] = B[i+1, int(viterbi_path[i+1])] # add the rest\\r\\n\\r\\n    return viterbi_loglik, viterbi_path\\r\\n    \\r\\n    \\r\\n\\r\\ndef statePosteriors(log_alpha, log_beta):\\r\\n    \"\"\"State posterior (gamma) probabilities in log domain.\\r\\n\\r\\n    Args:\\r\\n        log_alpha: NxM array of log forward (alpha) probabilities\\r\\n        log_beta: NxM array of log backward (beta) probabilities\\r\\n    where N is the number of frames, and M the number of states\\r\\n\\r\\n    Output:\\r\\n        log_gamma: NxM array of gamma probabilities for each of the M states in the model\\r\\n    \"\"\"\\r\\n    return log_alpha + log_beta - logsumexp(log_alpha[-1,:])\\r\\n\\r\\n\\r\\ndef updateMeanAndVar(X, log_gamma, varianceFloor=5.0):\\r\\n    \"\"\" Update Gaussian parameters with diagonal covariance\\r\\n\\r\\n    Args:\\r\\n         X: NxD array of feature vectors\\r\\n         log_gamma: NxM state posterior probabilities in log domain\\r\\n         varianceFloor: minimum allowed variance scalar\\r\\n    were N is the lenght of the observation sequence, D is the\\r\\n    dimensionality of the feature vectors and M is the number of\\r\\n    states in the model\\r\\n\\r\\n    Outputs:\\r\\n         means: MxD mean vectors for each state\\r\\n         covars: MxD covariance (variance) vectors for each state\\r\\n    \"\"\"\\r\\n    N, M = log_gamma.shape\\r\\n    D = X.shape[1]\\r\\n    \\r\\n    means  = np.zeros([M, D])\\r\\n    covars = np.zeros([M, D])\\r\\n    gamma = np.exp(log_gamma)\\r\\n    \\r\\n    for i in range(M):\\r\\n        means[i, :] = np.dot(X.T, gamma[:, i]) / np.sum(gamma[:, i])\\r\\n        x = X.T - means[i,:].reshape([D, 1])\\r\\n\\r\\n        result = 0\\r\\n        for j in range(N):\\r\\n            result = result + gamma[j, i] * np.outer(x[:, j], x[:, j])\\r\\n\\r\\n        covars[i, :] = np.diag(result) / np.sum(gamma[:, i])\\r\\n\\r\\n    covars[covars < varianceFloor] = varianceFloor\\r\\n\\r\\n    return means, covars\\r\\n\\r\\n\\r\\ndef compare(frames, example_frames):\\r\\n    \"\"\" Returns True if frames and example_frame are equal \"\"\"\\r\\n    \\r\\n    return np.isclose(frames, example_frames).all()',\n",
              " 'lab2_tools.py': b'import numpy as np\\r\\n\\r\\ndef logsumexp(arr, axis=0):\\r\\n    \"\"\"Computes the sum of arr assuming arr is in the log domain.\\r\\n    Returns log(sum(exp(arr))) while minimizing the possibility of\\r\\n    over/underflow.\\r\\n    \"\"\"\\r\\n    arr = np.rollaxis(arr, axis)\\r\\n    # Use the max to normalize, as with the log this is what accumulates\\r\\n    # the less errors\\r\\n    vmax = arr.max(axis=0)\\r\\n    if vmax.ndim > 0:\\r\\n        vmax[~np.isfinite(vmax)] = 0\\r\\n    elif not np.isfinite(vmax):\\r\\n        vmax = 0\\r\\n    with np.errstate(divide=\"ignore\"):\\r\\n        out = np.log(np.sum(np.exp(arr - vmax), axis=0))\\r\\n        out += vmax\\r\\n        return out\\r\\n\\r\\ndef log_multivariate_normal_density_diag(X, means, covars):\\r\\n    \"\"\"Compute Gaussian log-density at X for a diagonal model\\r\\n\\r\\n    Args:\\r\\n        X: array like, shape (n_observations, n_features)\\r\\n        means: array like, shape (n_components, n_features)\\r\\n        covars: array like, shape (n_components, n_features)\\r\\n\\r\\n    Output:\\r\\n        lpr: array like, shape (n_observations, n_components)\\r\\n    From scikit-learn/sklearn/mixture/gmm.py\\r\\n    \"\"\"\\r\\n    n_samples, n_dim = X.shape\\r\\n    lpr = -0.5 * (n_dim * np.log(2 * np.pi) + np.sum(np.log(covars), 1)\\r\\n                  + np.sum((means ** 2) / covars, 1)\\r\\n                  - 2 * np.dot(X, (means / covars).T)\\r\\n                  + np.dot(X ** 2, (1.0 / covars).T))\\r\\n    return lpr\\r\\n',\n",
              " 'lab3_proto.py': b'import numpy as np\\r\\nfrom lab3_tools import *\\r\\nfrom lab2_proto import *\\r\\nfrom lab2_tools import *\\r\\n\\r\\ndef words2phones(wordList, pronDict, addSilence=True, addShortPause=True):\\r\\n   \"\"\" word2phones: converts word level to phone level transcription adding silence\\r\\n\\r\\n   Args:\\r\\n      wordList: list of word symbols\\r\\n      pronDict: pronunciation dictionary. The keys correspond to words in wordList\\r\\n      addSilence: if True, add initial and final silence\\r\\n      addShortPause: if True, add short pause model \"sp\" at end of each word\\r\\n   Output:\\r\\n      list of phone symbols\\r\\n   \"\"\"\\r\\n\\r\\n   phoneSymb = []\\r\\n\\r\\n   for digit in wordList:\\r\\n      phoneSymb += pronDict[digit]\\r\\n\\r\\n   if addSilence: phoneSymb = [\\'sil\\'] + phoneSymb + [\\'sil\\']\\r\\n   if addShortPause: phoneSymb += [\\'sp\\'] \\r\\n\\r\\n   return phoneSymb\\r\\n\\r\\n   \\r\\ndef forcedAlignment(lmfcc, phoneHMMs, phoneTrans):\\r\\n    \"\"\" forcedAlignmen: aligns a phonetic transcription at the state level\\r\\n\\r\\n    Args:\\r\\n       lmfcc: NxD array of MFCC feature vectors (N vectors of dimension D)\\r\\n              computed the same way as for the training of phoneHMMs\\r\\n       phoneHMMs: set of phonetic Gaussian HMM models\\r\\n       phoneTrans: list of phonetic symbols to be aligned including initial and\\r\\n                   final silence\\r\\n\\r\\n    Returns:\\r\\n       list of strings in the form phoneme_index specifying, for each time step\\r\\n       the state from phoneHMMs corresponding to the viterbi path.\\r\\n    \"\"\"\\r\\n    obsloglik = log_multivariate_normal_density_diag(lmfcc, utteranceHMM[\\'means\\'], utteranceHMM[\\'covars\\'])\\r\\n    path, best_score = viterbi(obsloglik, utteranceHMM[\\'startprob\\'][:-1], utteranceHMM[\\'transmat\\'][:-1, :-1])\\r\\n    \\r\\n    phones = sorted(phoneHMMs.keys())\\r\\n    states = {phone: phoneHMMs[phone][\\'means\\'].shape[0] for phone in phones}\\r\\n    \\r\\n    stateTrans = [phone + \\'_\\' + str(stateid) for phone in phoneTrans for stateid in range(states[phone])]\\r\\n    aligned = [stateTrans[int(idx)] for idx in path]\\r\\n    \\r\\n    return aligned\\r\\n    \\r\\n    \\r\\n\\r\\ndef hmmLoop(hmmmodels, namelist=None):\\r\\n    \"\"\" Combines HMM models in a loop\\r\\n\\r\\n    Args:\\r\\n       hmmmodels: list of dictionaries with the following keys:\\r\\n           name: phonetic or word symbol corresponding to the model\\r\\n           startprob: M+1 array with priori probability of state\\r\\n           transmat: (M+1)x(M+1) transition matrix\\r\\n           means: MxD array of mean vectors\\r\\n           covars: MxD array of variances\\r\\n       namelist: list of model names that we want to combine, if None,\\r\\n                 all the models in hmmmodels are used\\r\\n\\r\\n    D is the dimension of the feature vectors\\r\\n    M is the number of emitting states in each HMM model (could be\\r\\n      different in each model)\\r\\n\\r\\n    Output\\r\\n       combinedhmm: dictionary with the same keys as the input but\\r\\n                    combined models\\r\\n       stateMap: map between states in combinedhmm and states in the\\r\\n                 input models.\\r\\n\\r\\n    Examples:\\r\\n       phoneLoop = hmmLoop(phoneHMMs)\\r\\n       wordLoop = hmmLoop(wordHMMs, [\\'o\\', \\'z\\', \\'1\\', \\'2\\', \\'3\\'])\\r\\n    \"\"\"\\r\\n',\n",
              " 'lab3_tools.py': b'import numpy as np\\r\\nimport os\\r\\nfrom pysndfile import sndio\\r\\n\\r\\ndef path2info(path):\\r\\n    \"\"\"\\r\\n    path2info: parses paths in the TIDIGIT format and extracts information\\r\\n               about the speaker and the utterance\\r\\n\\r\\n    Example:\\r\\n    path2info(\\'tidigits/disc_4.1.1/tidigits/train/man/ae/z9z6531a.wav\\')\\r\\n    \"\"\"\\r\\n    rest, filename = os.path.split(path)\\r\\n    rest, speakerID = os.path.split(rest)\\r\\n    rest, gender = os.path.split(rest)\\r\\n    digits = filename[:-5]\\r\\n    repetition = filename[-5]\\r\\n    return gender, speakerID, digits, repetition\\r\\n\\r\\ndef loadAudio(filename):\\r\\n    \"\"\"\\r\\n    loadAudio: loads audio data from file using pysndfile\\r\\n\\r\\n    Note that, by default pysndfile converts the samples into floating point\\r\\n    numbers and rescales them in the range [-1, 1]. This is avoided by specifying\\r\\n    the option dtype=np.int16 which keeps both the original data type and range\\r\\n    of values.\\r\\n    \"\"\"\\r\\n    sndobj = sndio.read(filename, dtype=np.int16)\\r\\n    samplingrate = sndobj[1]\\r\\n    samples = np.array(sndobj[0])\\r\\n    return samples, samplingrate\\r\\n\\r\\ndef frames2trans(sequence, outfilename=None, timestep=0.01):\\r\\n    \"\"\"\\r\\n    Outputs a standard transcription given a frame-by-frame\\r\\n    list of strings.\\r\\n\\r\\n    Example (using functions from Lab 1 and Lab 2):\\r\\n    phones = [\\'sil\\', \\'sil\\', \\'sil\\', \\'ow\\', \\'ow\\', \\'ow\\', \\'ow\\', \\'ow\\', \\'sil\\', \\'sil\\']\\r\\n    trans = frames2trans(phones, \\'oa.lab\\')\\r\\n\\r\\n    Then you can use, for example wavesurfer to open the wav file and the transcription\\r\\n    \"\"\"\\r\\n    sym = sequence[0]\\r\\n    start = 0\\r\\n    end = 0\\r\\n    trans = \\'\\'\\r\\n    for t in range(len(sequence)):\\r\\n        if sequence[t] != sym:\\r\\n            trans = trans + str(start) + \\' \\' + str(end) + \\' \\' + sym + \\'\\\\n\\'\\r\\n            sym = sequence[t]\\r\\n            start = end\\r\\n        end = end + timestep\\r\\n    trans = trans + str(start) + \\' \\' + str(end) + \\' \\' + sym + \\'\\\\n\\'\\r\\n    if outfilename != None:\\r\\n        with open(outfilename, \\'w\\') as f:\\r\\n            f.write(trans)\\r\\n    return trans\\r\\n\\r\\n        \\r\\n',\n",
              " 'prondict.py': b\"prondict = {} \\r\\nprondict['o'] = ['ow']\\r\\nprondict['z'] = ['z', 'iy', 'r', 'ow']\\r\\nprondict['1'] = ['w', 'ah', 'n']\\r\\nprondict['2'] = ['t', 'uw']\\r\\nprondict['3'] = ['th', 'r', 'iy']\\r\\nprondict['4'] = ['f', 'ao', 'r']\\r\\nprondict['5'] = ['f', 'ay', 'v']\\r\\nprondict['6'] = ['s', 'ih', 'k', 's']\\r\\nprondict['7'] = ['s', 'eh', 'v', 'ah', 'n']\\r\\nprondict['8'] = ['ey', 't']\\r\\nprondict['9'] = ['n', 'ay', 'n']\\r\\n\"}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6OMZ3hM9z-L9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from lab1_proto import *\n",
        "from lab2_proto import *\n",
        "from lab3_proto import *\n",
        "from lab1_tools import *\n",
        "from lab2_tools import *\n",
        "from lab3_tools import *\n",
        "from prondict import prondict\n",
        "\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import keras"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XnP2-oIL_IEX",
        "colab_type": "text"
      },
      "source": [
        "## Check examples\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9HnRiMcwA7d5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "example = np.load('/content/drive/My Drive/Lab3/lab3_example.npz', allow_pickle=True)['example'].item()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q6ScIE_E0tFj",
        "colab_type": "code",
        "outputId": "196c510a-ded1-45d2-b203-9c160e0cd960",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 55
        }
      },
      "source": [
        "phoneHMMs = np.load('/content/drive/My Drive/Lab3/lab2_models_all.npz', allow_pickle=True)['phoneHMMs'].item()\n",
        "phones = sorted(phoneHMMs.keys())\n",
        "nstates = {phone: phoneHMMs[phone]['means'].shape[0] for phone in phones}\n",
        "stateList = [ph + '_' + str(id) for ph in phones for id in range(nstates[ph])]\n",
        "print(stateList)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['ah_0', 'ah_1', 'ah_2', 'ao_0', 'ao_1', 'ao_2', 'ay_0', 'ay_1', 'ay_2', 'eh_0', 'eh_1', 'eh_2', 'ey_0', 'ey_1', 'ey_2', 'f_0', 'f_1', 'f_2', 'ih_0', 'ih_1', 'ih_2', 'iy_0', 'iy_1', 'iy_2', 'k_0', 'k_1', 'k_2', 'n_0', 'n_1', 'n_2', 'ow_0', 'ow_1', 'ow_2', 'r_0', 'r_1', 'r_2', 's_0', 's_1', 's_2', 'sil_0', 'sil_1', 'sil_2', 'sp_0', 't_0', 't_1', 't_2', 'th_0', 'th_1', 'th_2', 'uw_0', 'uw_1', 'uw_2', 'v_0', 'v_1', 'v_2', 'w_0', 'w_1', 'w_2', 'z_0', 'z_1', 'z_2']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aSLjfSKe4DKw",
        "colab_type": "code",
        "outputId": "bab19e60-24f2-476a-8c85-c4c46c606eee",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 107
        }
      },
      "source": [
        "filename = '/content/drive/My Drive/tidigits/disc_4.1.1/tidigits/train/man/nw/z43a.wav'\n",
        "samples, samplingrate = loadAudio(filename)\n",
        "lmfcc = mfcc(samples)\n",
        "print(\"LMFCC Shape: \", lmfcc.shape)\n",
        "\n",
        "wordTrans = list(path2info(filename)[2])\n",
        "print(\"Sequence of digits: \", wordTrans)\n",
        "\n",
        "print(\"Pronunciation dictionary: \", prondict)\n",
        "\n",
        "phoneTrans = words2phones(wordTrans, prondict)\n",
        "print(\"Phone level transcription: \", phoneTrans)\n",
        "utteranceHMM = concatHMMs(phoneHMMs, phoneTrans)\n",
        "stateTrans = [phone + '_' + str(stateid) for phone in phoneTrans\n",
        "              for stateid in range(nstates[phone])]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "LMFCC Shape:  (178, 13)\n",
            "Sequence of digits:  ['z', '4', '3']\n",
            "Pronunciation dictionary:  {'o': ['ow'], 'z': ['z', 'iy', 'r', 'ow'], '1': ['w', 'ah', 'n'], '2': ['t', 'uw'], '3': ['th', 'r', 'iy'], '4': ['f', 'ao', 'r'], '5': ['f', 'ay', 'v'], '6': ['s', 'ih', 'k', 's'], '7': ['s', 'eh', 'v', 'ah', 'n'], '8': ['ey', 't'], '9': ['n', 'ay', 'n']}\n",
            "Phone level transcription:  ['sil', 'z', 'iy', 'r', 'ow', 'f', 'ao', 'r', 'th', 'r', 'iy', 'sil', 'sp']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uFYkWvFo_Qjl",
        "colab_type": "code",
        "outputId": "fe4f51bf-91e9-4331-bf85-97c98723e480",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 305
        }
      },
      "source": [
        "# Compare with examples\n",
        "obsloglik = log_multivariate_normal_density_diag(lmfcc, utteranceHMM['means'], utteranceHMM['covars'])\n",
        "viterbi_loglik, viterbi_path = viterbi(obsloglik, np.log(utteranceHMM['startprob']), np.log(utteranceHMM['transmat']))\n",
        "#viterbiStateTrans = list(np.array(stateTrans)[viterbi_path])\n",
        "\n",
        "print('Comparing obsloglik...', compare(obsloglik, example['obsloglik'][:, :-2]))\n",
        "print('Comparing viterbiPath...', compare(viterbi_path, example['viterbiPath']))\n",
        "#print('Comparing viterbiStateTrans...', np.all(viterbiStateTrans == example['viterbiStateTrans']))\n",
        "\n",
        "frames = frames2trans(viterbiStateTrans, outfilename= ''.join(path2info(filename)[2:]) + '.lab')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Comparing obsloglik... False\n",
            "Comparing viterbiPath... False\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:3: RuntimeWarning: divide by zero encountered in log\n",
            "  This is separate from the ipykernel package so we can avoid doing imports until\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-31-50cf485a0183>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Comparing obsloglik...'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcompare\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobsloglik\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexample\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'obsloglik'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Comparing viterbiPath...'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcompare\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mviterbi_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexample\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'viterbiPath'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Comparing viterbiStateTrans...'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mviterbiStateTrans\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mexample\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'viterbiStateTrans'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0mframes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mframes2trans\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mviterbiStateTrans\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutfilename\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0;34m''\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath2info\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'.lab'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'viterbiStateTrans' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "94p1Oz-cEsBe",
        "colab_type": "code",
        "outputId": "661db27e-03dd-41a2-bf53-50abf0637afa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 243
        }
      },
      "source": [
        "obsloglik"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[-82.85615934, -77.77520492, -78.78912809, ..., -77.77520492,\n",
              "        -78.78912809, -77.77520492],\n",
              "       [-82.64629092, -75.68935466, -78.4682569 , ..., -75.68935466,\n",
              "        -78.4682569 , -75.68935466],\n",
              "       [-81.28144137, -74.7891467 , -76.77156599, ..., -74.7891467 ,\n",
              "        -76.77156599, -74.7891467 ],\n",
              "       ...,\n",
              "       [-78.94201025, -88.97211724, -80.73016898, ..., -88.97211724,\n",
              "        -80.73016898, -88.97211724],\n",
              "       [-77.97751766, -86.49199766, -79.0998656 , ..., -86.49199766,\n",
              "        -79.0998656 , -86.49199766],\n",
              "       [-76.34772424, -81.64468937, -77.4851362 , ..., -81.64468937,\n",
              "        -77.4851362 , -81.64468937]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2F9FTV6jEtsn",
        "colab_type": "code",
        "outputId": "fc68b276-9d72-48d9-c768-25500db50de0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 243
        }
      },
      "source": [
        "example['obsloglik']"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[-82.85615934, -77.77520492, -78.78912809, ..., -82.85615934,\n",
              "        -77.77520492, -78.78912809],\n",
              "       [-82.64629092, -75.68935466, -78.4682569 , ..., -82.64629092,\n",
              "        -75.68935466, -78.4682569 ],\n",
              "       [-81.28144137, -74.7891467 , -76.77156599, ..., -81.28144137,\n",
              "        -74.7891467 , -76.77156599],\n",
              "       ...,\n",
              "       [-78.94201025, -88.97211724, -80.73016898, ..., -78.94201025,\n",
              "        -88.97211724, -80.73016898],\n",
              "       [-77.97751766, -86.49199766, -79.0998656 , ..., -77.97751766,\n",
              "        -86.49199766, -79.0998656 ],\n",
              "       [-76.34772424, -81.64468937, -77.4851362 , ..., -76.34772424,\n",
              "        -81.64468937, -77.4851362 ]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bng8M00ahb24",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "stateTrans[10]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "obBFQuwOheMo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "frames2trans(viterbiStateTrans, outfilename='z43a.lab')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "addeh9oShjCY",
        "colab_type": "text"
      },
      "source": [
        "# 4.3 Feature Extraction"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dUkLiuEhhf04",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "traindata = []\n",
        "for root, dirs, files in os.walk('tidigits/disc_4.1.1/tidigits/train'):\n",
        "  for file in files:\n",
        "    if file.endswith('.wav'):\n",
        "      filename = os.path.join(root, file)\n",
        "      samples, samplingrate = loadAudio(filename)\n",
        "#...your code for feature extraction and forced alignment\n",
        "      traindata.append({'filename': filename, 'lmfcc': lmfcc,\n",
        "                        'mspec': 'mspec', 'targets': targets})\n",
        "      \n",
        "    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vE1sI669iKqD",
        "colab_type": "text"
      },
      "source": [
        "# 4.4 Training and Validation Sets"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d5ZHt24Sh8JJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Split the training data into a training set (roughly 90%) and validation set (remaining 10%).\n",
        "# Make sure that there is a similar distribution of men and women in both sets, and that each\n",
        "# speaker is only included in one of the two sets. The last requirement is to ensure that we do not\n",
        "# get artificially good results on the validation set. Explain how you selected the two data sets."
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DoY6WbNkiV84",
        "colab_type": "text"
      },
      "source": [
        "# 4.5 Acoustic Context (Dynamic Features)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gw1hdtUBiU1H",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# For each utterance and time step, stack 7 MFCC or filterbank features symmetrically distributed\n",
        "# around the current time step. That is, at time n, stack the features at times [n􀀀3; n􀀀\n",
        "# 2; n􀀀1; n; n+1; n+2; n+3]). At the beginning and end of each utterance, use mirrored feature\n",
        "# vectors in place of the missing vectors. For example at the beginning use feature vectors with\n",
        "# indexes [3; 2; 1; 0; 1; 2; 3] for the first time step, [2; 1; 0; 1; 2; 3; 4] for the second time step, and so\n",
        "# on. The “boundary effect” is usually not very important because each utterance begins and ends\n",
        "# with silence."
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W9vUqa_2jmsP",
        "colab_type": "text"
      },
      "source": [
        "# 4.6 Feature Standardisation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p718kAvkjlul",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}