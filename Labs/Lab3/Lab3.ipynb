{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Lab3.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/bjelikj/DT2119/blob/Lab3_Andres/Labs/Lab3/Lab3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_300NuWNwpuZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "try:\n",
        "  import google.colab\n",
        "  IN_COLAB = True\n",
        "except:\n",
        "  IN_COLAB = False\n",
        "\n",
        "if IN_COLAB:\n",
        "    from google.colab import drive\n",
        "    drive.mount('/content/drive/')\n",
        "\n",
        "reload_files = True\n",
        "# feature = 'lmfcc'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oP6t6vObxeDP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\"\"\"\n",
        "Necessary files:\n",
        "- lab1_proto.py\n",
        "- lab1_tools.py\n",
        "- lab2_proto.py\n",
        "- lab2_tools.py\n",
        "- lab3_proto.py\n",
        "- lab3_tools.py\n",
        "- prondict.py\n",
        "- standardization.py\n",
        "\n",
        "If not uploaded to Google Drive:\n",
        "- lab2_models_all.npz\n",
        "- lab3_example.npz\n",
        "\"\"\"\n",
        "\n",
        "if reload_files:\n",
        "  # %pwd\n",
        "  !pwd\n",
        "  if IN_COLAB:\n",
        "      !rm -r ./*.py\n",
        "\n",
        "  from google.colab import files\n",
        "  files.upload()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6OMZ3hM9z-L9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from lab1_proto import *\n",
        "from lab2_proto import *\n",
        "from lab3_proto import *\n",
        "from lab1_tools import *\n",
        "from lab2_tools import *\n",
        "from lab3_tools import *\n",
        "from prondict import prondict\n",
        "from standardization import *\n",
        "\n",
        "import numpy as np\n",
        "import os"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XnP2-oIL_IEX",
        "colab_type": "text"
      },
      "source": [
        "## Check examples\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9HnRiMcwA7d5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "example = np.load('/content/drive/My Drive/Lab3/lab3_example.npz', allow_pickle=True)['example'].item()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dknvV5JBRyl4",
        "colab_type": "text"
      },
      "source": [
        "# 4.1 Target Class Definition"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q6ScIE_E0tFj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "phoneHMMs = np.load('/content/drive/My Drive/Lab3/lab2_models_all.npz', allow_pickle=True)['phoneHMMs'].item()\n",
        "phones = sorted(phoneHMMs.keys())\n",
        "nstates = {phone: phoneHMMs[phone]['means'].shape[0] for phone in phones}\n",
        "stateList = [ph + '_' + str(id) for ph in phones for id in range(nstates[ph])]\n",
        "print(stateList)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6SCaR5JzR31i",
        "colab_type": "text"
      },
      "source": [
        "# 4.2 Forced Alignment"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aSLjfSKe4DKw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "filename = '/content/drive/My Drive/tidigits/disc_4.1.1/tidigits/train/man/nw/z43a.wav'\n",
        "samples, samplingrate = loadAudio(filename)\n",
        "lmfcc = mfcc(samples)\n",
        "print(\"LMFCC Shape: \", lmfcc.shape)\n",
        "\n",
        "wordTrans = list(path2info(filename)[2])\n",
        "print(\"Sequence of digits: \", wordTrans)\n",
        "\n",
        "print(\"Pronunciation dictionary: \", prondict)\n",
        "\n",
        "phoneTrans = words2phones(wordTrans, prondict)\n",
        "print(\"Phone level transcription: \", phoneTrans)\n",
        "utteranceHMM = concatHMMs(phoneHMMs, phoneTrans)\n",
        "\n",
        "stateTrans = [phone + '_' + str(stateid) for phone in phoneTrans\n",
        "              for stateid in range(nstates[phone])]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uFYkWvFo_Qjl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Compare with examples\n",
        "for i in example['utteranceHMM'].keys():\n",
        "    print(compare(utteranceHMM[i], example['utteranceHMM'][i]))\n",
        "\n",
        "obsloglik = log_multivariate_normal_density_diag(lmfcc, utteranceHMM['means'], utteranceHMM['covars'])\n",
        "viterbi_loglik, viterbi_path = viterbi(obsloglik, np.log(utteranceHMM['startprob']), np.log(utteranceHMM['transmat']))\n",
        "viterbiStateTrans = [stateTrans[idx] for idx in viterbi_path.astype(np.int64)] # Forced Alignment\n",
        "\n",
        "print('Comparing obsloglik...', compare(obsloglik, example['obsloglik']))\n",
        "print('Comparing viterbiPath...', compare(viterbi_path, example['viterbiPath']))\n",
        "print('Comparing viterbiStateTrans...', np.all(viterbiStateTrans == example['viterbiStateTrans']))\n",
        "\n",
        "frames = frames2trans(viterbiStateTrans, outfilename= ''.join(path2info(filename)[2:]) + '.lab')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t7WOETbIRsXv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from IPython.display import Image\n",
        "Image(filename='/content/drive/My Drive/Lab3/z43a_wavesurfer.png')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "addeh9oShjCY",
        "colab_type": "text"
      },
      "source": [
        "# 4.3 Feature Extraction"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zD6858tUPETU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def extract_features_and_targets(filename):\n",
        "    \"\"\" extract_features_and_targets: extracts lmfcc, mspecc and \n",
        "        targets from a *.wav sound file\n",
        "\n",
        "    Args:\n",
        "        filename: location of .wav file\n",
        "\n",
        "    Returns:\n",
        "        lmfcc: liftered mfcc features\n",
        "        mspec: filterbank features\n",
        "        targets: indices of the target state for each feature\n",
        "    \"\"\"\n",
        "    samples, samplingrate = loadAudio(filename)\n",
        "    wordTrans = list(path2info(filename)[2])\n",
        "    phoneTrans = words2phones(wordTrans, prondict)\n",
        "    stateTrans = [phone + '_' + str(stateid) for phone in phoneTrans \n",
        "                  for stateid in range(nstates[phone])]\n",
        "    utteranceHMM = concatHMMs(phoneHMMs, phoneTrans)\n",
        "\n",
        "    stateTrans = [phone + '_' + str(stateid) for phone in phoneTrans\n",
        "              for stateid in range(nstates[phone])]\n",
        "\n",
        "    lmfcc = mfcc(samples)\n",
        "    mspec_ = mspec(samples)\n",
        "\n",
        "    obsloglik = log_multivariate_normal_density_diag(lmfcc, utteranceHMM['means'], utteranceHMM['covars'])\n",
        "    viterbi_loglik, viterbi_path = viterbi(obsloglik, np.log(utteranceHMM['startprob']), np.log(utteranceHMM['transmat']), True)\n",
        "    targets = [stateTrans[idx] for idx in viterbi_path.astype(np.int64)] \n",
        "\n",
        "    return lmfcc, mspec_, targets"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2I1uUxkc-Tn1",
        "colab_type": "text"
      },
      "source": [
        "Extract and save lmfcc and mspec features, and their associated targets"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dUkLiuEhhf04",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\"\"\"\n",
        "from tqdm import tqdm\n",
        "traindata = []\n",
        "for root, dirs, files in tqdm(os.walk('/content/drive/My Drive/tidigits/disc_4.1.1/tidigits/train'), desc='dirs'):\n",
        "  for file in files:\n",
        "    if file.endswith('.wav'):\n",
        "      filename = os.path.join(root, file)\n",
        "      samples, samplingrate = loadAudio(filename)\n",
        "      lmfcc, mspec_, targets =  extract_features_and_targets(filename)\n",
        "      traindata.append({'filename': filename, 'lmfcc': lmfcc,\n",
        "                        'mspec': mspec_, 'targets': targets})\n",
        "\n",
        "np.savez('/content/drive/My Drive/Lab3/traindata.npz', traindata=traindata)\n",
        "\"\"\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z9pxdzXZbVU2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\"\"\"\n",
        "testdata = []\n",
        "for root, dirs, files in tqdm(os.walk('/content/drive/My Drive/tidigits/disc_4.2.1/tidigits/test'), desc='dirs'):\n",
        "  for file in files:\n",
        "    if file.endswith('.wav'):\n",
        "      filename = os.path.join(root, file)\n",
        "      samples, samplingrate = loadAudio(filename)\n",
        "      lmfcc, mspec_, targets =  extract_features_and_targets(filename)\n",
        "      testdata.append({'filename': filename, 'lmfcc': lmfcc,\n",
        "                        'mspec': mspec_, 'targets': targets})\n",
        "\n",
        "np.savez('/content/drive/My Drive/Lab3/testdata.npz', testdata=testdata)\n",
        "\"\"\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vE1sI669iKqD",
        "colab_type": "text"
      },
      "source": [
        "# 4.4 Training and Validation Sets"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HJh3VAsecThl",
        "colab_type": "text"
      },
      "source": [
        "##### Split the training data into a training set (roughly 90%) and validation set (remaining 10%). Make sure that there is a similar distribution of men and women in both sets, and that each speaker is only included in one of the two sets. The last requirement is to ensure that we do not get artificially good results on the validation set. Explain how you selected the two data sets.\n",
        "\n",
        "**You should specify both the training and validation data with the respective targets. What is the purpose of the validation data?**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0gtbsZ2lce_o",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#train_data = np.load('/content/drive/My Drive/Lab3/traindata.npz', allow_pickle=True)['traindata']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "19A9940o3jCQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train_val_split(data):\n",
        "  \"\"\"train_val_split: splits dataset into train and validation sets\n",
        "\n",
        "  Args:\n",
        "    data: dataset to be split\n",
        "  \"\"\"\n",
        "  MAN_SAMPLES = 4235\n",
        "  WOMAN_SAMPLES = 4388\n",
        "  VAL_PER = 0.1\n",
        "  SAMPLES_PER_PERSON = 77\n",
        "\n",
        "  nsamples = len(data)\n",
        "  approx_val_size = int(0.1 * nsamples)\n",
        "  val_class_people_count = int(approx_val_size / (SAMPLES_PER_PERSON))\n",
        "\n",
        "  if val_class_people_count % 2 != 0:\n",
        "      val_class_people_count += 1\n",
        "\n",
        "  val_size = val_class_people_count * SAMPLES_PER_PERSON\n",
        "  training_size = nsamples - val_size\n",
        "\n",
        "  samples_per_gender = int(val_size / 2)\n",
        "\n",
        "  val_data = [data[i] for i in range(0, samples_per_gender)]\n",
        "  val_data.extend([data[i] for i in range(MAN_SAMPLES, MAN_SAMPLES + samples_per_gender)])\n",
        "  training_data = [sample for sample in data if sample['filename'] not in [x['filename'] for x in val_data]]\n",
        "\n",
        "  np.save('/content/drive/My Drive/Lab3/training_data.npy', training_data)\n",
        "  np.save('/content/drive/My Drive/Lab3/validation_data.npy', val_data)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cvI0fx055Yky",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#train_val_split(train_data)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DoY6WbNkiV84",
        "colab_type": "text"
      },
      "source": [
        "# 4.5 Acoustic Context (Dynamic Features)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LirZzxUH6Ccv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# if len(os.listdir('/content/drive/My Drive/Lab3_features')) == 0:\n",
        "#   train_data = np.load('/content/drive/My Drive/Lab3/training_data.npy', allow_pickle=True)\n",
        "#   val_data = np.load('/content/drive/My Drive/Lab3/validation_data.npy', allow_pickle=True)\n",
        "#   test_data = np.load('/content/drive/My Drive/Lab3/testdata.npz', allow_pickle=True)['testdata']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gw1hdtUBiU1H",
        "colab_type": "text"
      },
      "source": [
        "#### For each utterance and time step, stack 7 MFCC or filterbank features symmetrically distributed around the current time step. That is, at time n, stack the features at times [n-3; n-2; n-1; n; n+1; n+2; n+3]). At the beginning and end of each utterance, use mirrored feature vectors in place of the missing vectors. For example at the beginning use feature vectors with indexes [3; 2; 1; 0; 1; 2; 3] for the first time step, [2; 1; 0; 1; 2; 3; 4] for the second time step, and so on. The “boundary effect” is usually not very important because each utterance begins and ends with silence."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uC93bO4N_0nB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# from tqdm import tqdm\n",
        "# def create_dynamic_features(data, feature_type):\n",
        "#     \"\"\" create_dynamic_features: Creates dynamic features by concatinated 7 \n",
        "#         lmfcc or mspec featues together for each step\n",
        "\n",
        "#     Args:\n",
        "#         data: list of dictionaries with keys: 'lmfcc', 'mspec' and 'targets'\n",
        "    \n",
        "#     Returns:\n",
        "#         lmfcc_features: [NxD_lmfcc * 7] where N = number of all concatinated samples of all words in data\n",
        "#         mspec_features: [NxD_mspec * 7] where N = of all concatinated samples of all words in data\n",
        "#         targets: [N,] index of state for each sample\n",
        "#     \"\"\"\n",
        "    \n",
        "#     D_lmfcc = data[0]['lmfcc'].shape[1]\n",
        "#     D_mspec = data[0]['mspec'].shape[1]\n",
        "#     N = sum([len(x['targets']) for x in data])\n",
        "\n",
        "#     # Features to be returned\n",
        "#     dynlmfcc_features = np.zeros((N, D_lmfcc * 7))\n",
        "#     dynmspec_features = np.zeros((N, D_mspec * 7))\n",
        "    \n",
        "#     # Targets to be returned\n",
        "#     targets = []\n",
        "#     # lmfcc_features = []\n",
        "#     # mspec_features = []\n",
        "\n",
        "#     if feature_type =='lmfcc':\n",
        "#       lmfcc_features = data[0]['lmfcc']\n",
        "#       for i,d in enumerate(data[1:]):\n",
        "#         lmfcc_features = np.vstack((lmfcc_features, d['lmfcc']))\n",
        "#     elif feature_type == 'mspec':\n",
        "#       mspec_features = data[0]['mspec']\n",
        "#       for i,d in enumerate(data[1:]):\n",
        "#         mspec_features = np.vstack((mspec_features, d['mspec'])) \n",
        "\n",
        "\n",
        "#     # through all data\n",
        "#     k = 0\n",
        "#     for x in tqdm(data): \n",
        "#         # if feature_type == 'lmfcc':\n",
        "#           # lmfcc_features.append(x['lmfcc'])\n",
        "#         # elif feature_type == 'mspec':\n",
        "#           # mspec_features.append(x['mspec'])\n",
        "\n",
        "#         # else:\n",
        "#         if not(feature_type == 'lmfcc' or feature == 'mspec'):\n",
        "#           times, dim = x['lmfcc'].shape\n",
        "#           # for each time step\n",
        "#           for i in range(times):\n",
        "#             if i < 3 or i >= times - 3:\n",
        "#               if feature_type == 'dynlmfcc':\n",
        "#                 dynlmfcc_features[k, :] = np.hstack(np.pad(x['lmfcc'], pad_width=((3, 3), (0, 0)), mode='reflect')[i:i+7, :])\n",
        "#               elif feature_type == 'dynmspec':\n",
        "#                 dynmspec_features[k, :] = np.hstack(np.pad(x['mspec'], pad_width=((3, 3), (0, 0)), mode='reflect')[i:i+7, :])\n",
        "#             else:\n",
        "#               if feature_type == 'dynlmfcc':\n",
        "#                 dynlmfcc_features[k,:] = np.hstack(x['lmfcc'][i-3:i+4, :])\n",
        "#               elif feature_type == 'dynmspec':\n",
        "#                 dynmspec_features[k,:] = np.hstack(x['mspec'][i-3:i+4, :])\n",
        "#             k +=1\n",
        "#         targets = targets + x['targets']\n",
        "\n",
        "#     if feature_type == 'lmfcc':\n",
        "#       # return np.asarray(lmfcc_features), targets\n",
        "#       return lmfcc_features, targets\n",
        "#     elif feature_type == 'mspec':\n",
        "#       # return np.asarray(mspec_features), targets\n",
        "#       return mspec_features, targets\n",
        "#     elif feature_type == 'dynlmfcc':\n",
        "#       return dynlmfcc_features, targets\n",
        "#     elif feature_type == 'dynmspec':\n",
        "#       return dynmspec_features, targets\n",
        "\n",
        "#     # return np.asarray(lmfcc_features), np.asarray(mspec_features), dynlmfcc_features, dynmspec_features, targets\n",
        "#     # return dynlmfcc_features, dynmspec_features, targets"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "31A8M7j6VTvR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tqdm import tqdm\n",
        "def create_dynamic_features(data, feature):\n",
        "    \"\"\" create_dynamic_features: Creates dynamic features by concatinated 7 \n",
        "        lmfcc or mspec featues together for each step\n",
        "\n",
        "    Args:\n",
        "        data: list of dictionaries with keys: 'lmfcc', 'mspec' and 'targets'\n",
        "    \n",
        "    Returns:\n",
        "        lmfcc_features: [NxD_lmfcc * 7] where N = number of all concatinated samples of all words in data\n",
        "        mspec_features: [NxD_mspec * 7] where N = of all concatinated samples of all words in data\n",
        "        targets: [N,] index of state for each sample\n",
        "    \"\"\"\n",
        "    \n",
        "    D_feature = data[0][feature].shape[1]\n",
        "    # D_mspec = data[0][feature].shape[1]\n",
        "    N = sum([len(x['targets']) for x in data])\n",
        "\n",
        "    # Features to be returned\n",
        "    dynamic_features = np.zeros((N, D_feature * 7))\n",
        "    # dynmspec_features = np.zeros((N, D_mspec * 7))\n",
        "    \n",
        "    # Targets to be returned\n",
        "    targets = []\n",
        "\n",
        "    # through all data\n",
        "    k = 0\n",
        "    for x in tqdm(data): \n",
        "\n",
        "        times, dim = x[feature].shape\n",
        "        # for each time step\n",
        "        for i in range(times):\n",
        "            if i < 3 or i >= times - 3:\n",
        "                dynamic_features[k, :] = np.hstack(np.pad(x[feature], pad_width=((3, 3), (0, 0)), mode='reflect')[i:i+7, :])\n",
        "                # dynmspec_features[k, :] = np.hstack(np.pad(x['mspec'], pad_width=((3, 3), (0, 0)), mode='reflect')[i:i+7, :])\n",
        "            else:\n",
        "                dynamic_features[k,:] = np.hstack(x[feature][i-3:i+4, :])\n",
        "                # dynmspec_features[k,:] = np.hstack(x['mspec'][i-3:i+4, :])\n",
        "            k +=1\n",
        "        targets = targets + x['targets']\n",
        "\n",
        "    # return dynlmfcc_features, dynmspec_features, targets\n",
        "    return dynamic_features, targets"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jJ2jyVl4VQYm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def create_non_dynamic_features(data, feature):\n",
        "    \"\"\" Puts lmfcc and mspec features in arrays that can used for training\n",
        "    Arg\n",
        "        data: list of dictionaries with keys: 'lmfcc', 'mspec' and 'targets'\n",
        "    \n",
        "    Output\n",
        "        lmfcc_features: [NxD_lmfcc] where N is nr of all concatinated samples of all words in data\n",
        "        mspec_features: [NxD_mspec] where N is nr of all concatinated samples of all words in data\n",
        "        targets: [N,] index of state for each sample\n",
        "    \"\"\"\n",
        "    \n",
        "    D_feature = data[0][feature].shape[1]\n",
        "    # D_mspec = data[0]['mspec'].shape[1]\n",
        "    N = sum([len(x['targets']) for x in data])\n",
        "\n",
        "    # Features to be returned\n",
        "    nondynamic_features = np.zeros((N,D_lmfcc))\n",
        "    # mspec_features = np.zeros((N,D_mspec))\n",
        "\n",
        "    # Targets to be returned\n",
        "    targets = []\n",
        "\n",
        "    # through all data\n",
        "    k = 0\n",
        "    for x in tqdm(data): \n",
        "        times, dim = x[feature].shape\n",
        "        ## for each timestep\n",
        "        for i in range(times):\n",
        "            nondynamic_features[k,:]=x[feature][i,:]\n",
        "            # mspec_features[k,:]=x['mspec'][i,:]\n",
        "            k +=1\n",
        "        targets = targets + x['targets']\n",
        "    return nondynamic_features, targets"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r6rZ9PAvCAak",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Features & Dynamic features\n",
        "\n",
        "def getFeatures(feature):\n",
        "  if os.path.exists('/content/drive/My Drive/Lab3_features/' + feature + '.npz') == False:\n",
        "    train_data = np.load('/content/drive/My Drive/Lab3/training_data.npy', allow_pickle=True)\n",
        "    val_data = np.load('/content/drive/My Drive/Lab3/validation_data.npy', allow_pickle=True)\n",
        "    test_data = np.load('/content/drive/My Drive/Lab3/testdata.npz', allow_pickle=True)['testdata']\n",
        "    # lmfcc_train_x, mspec_train_x, dynlmfcc_train_x, dynmspec_train_x, train_y = create_dynamic_features(train_data)\n",
        "    # lmfcc_val_x, mspec_val_x, dynlmfcc_val_x, dynmspec_val_x, val_y = create_dynamic_features(val_data)\n",
        "    # lmfcc_test_x, mspec_test_x, dynlmfcc_test_x, dynmspec_test_x, test_y = create_dynamic_features(test_data) \n",
        "    # dynlmfcc_train_x, dynmspec_train_x, train_y = create_dynamic_features(train_data)\n",
        "    # train_x, train_y = create_dynamic_features(train_data, feature)\n",
        "    # val_x, val_y = create_dynamic_features(val_data, feature)\n",
        "    # test_x, test_y = create_dynamic_features(test_data, feature)\n",
        "\n",
        "    if feature == 'lmfcc' or 'mspec':\n",
        "      train_x, train_y = create_non_dynamic_features(train_data, feature)\n",
        "      val_x, val_y = create_non_dynamic_features(val_data, feature)\n",
        "      test_x, test_y = create_non_dynamic_features(test_data, feature)\n",
        "    else:\n",
        "      train_x, train_y = create_dynamic_features(train_data, feature)\n",
        "      val_x, val_y = create_dynamic_features(val_data, feature)\n",
        "      test_x, test_y = create_dynamic_features(test_data, feature)\n",
        "\n",
        "    np.save('/content/drive/My Drive/Lab3_features/train_y.npy', train_y)\n",
        "    np.save('/content/drive/My Drive/Lab3_features/val_y.npy', val_y)\n",
        "    np.save('/content/drive/My Drive/Lab3_features/test_y.npy', test_y)\n",
        "\n",
        "    np.savez_compressed('/content/drive/My Drive/Lab3_features/' + feature, train_x=train_x, val_x=val_x, test_x=test_x)\n",
        "    # if feature == 'lmfcc':\n",
        "    #   np.savez_compressed('/content/drive/My Drive/Lab3_features/lmfcc', lmfcc_train_x=train_x, lmfcc_val_x=val_x, lmfcc_test_x=test_x)\n",
        "    # if feature == 'mspec':\n",
        "    #   np.savez_compressed('/content/drive/My Drive/Lab3_features/mspec', mspec_train_x=train_x, mspec_val_x=val_x, mspec_test_x=test_x)\n",
        "    # if feature == 'dynlmfcc':\n",
        "    #   np.savez_compressed('/content/drive/My Drive/Lab3_features/dynlmfcc', dynlmfcc_train_x=train_x, dynlmfcc_val_x=val_x, dynlmfcc_test_x=test_x)\n",
        "    # if feature == 'dynmspec':\n",
        "    #   np.savez_compressed('/content/drive/My Drive/Lab3_features/dynmspec', dynmspec_train_x=train_x, dynmspec_val_x=val_x, dynmspec_test_x=test_x)\n",
        "\n",
        "    # dynlmfcc_val_x, dynmspec_val_x, val_y = create_dynamic_features(val_data)\n",
        "    # dynlmfcc_test_x, dynmspec_test_x, test_y = create_dynamic_features(test_data)\n",
        "  else:\n",
        "    loaded = np.load('/content/drive/My Drive/Lab3_features/' + feature + '.npz', allow_pickle=True)\n",
        "    train_x =  loaded['train_x']\n",
        "    val_x = loaded['val_x']\n",
        "    test_x = loaded['test_x']\n",
        "    train_y = np.load('/content/drive/My Drive/Lab3_features/train_y.npy')\n",
        "    val_y = np.load('/content/drive/My Drive/Lab3_features/val_y.npy')\n",
        "    test_y = np.load('/content/drive/My Drive/Lab3_features/test_y.npy')\n",
        "\n",
        "  return train_x, val_x, test_x, train_y, val_y, test_y"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W9vUqa_2jmsP",
        "colab_type": "text"
      },
      "source": [
        "# 4.6 Feature Standardisation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2Gob6Vu61tmT",
        "colab_type": "text"
      },
      "source": [
        "Normalization over the complete training set"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p718kAvkjlul",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def normalizeFeatures(feature, train_x, val_x, test_x):\n",
        "\n",
        "  # if feature == 'lmfcc':\n",
        "    if os.path.exists('/content/drive/My Drive/Lab3_features/normalized/' + feature + '_norm.npz') == False:\n",
        "      # loaded = np.load('/content/drive/My Drive/Lab3_features/' + feature '.npz', allow_pickle=True)\n",
        "      # train_x =  loaded['train_x']\n",
        "      # val_x = loaded['val_x']\n",
        "      # test_x = loaded['test_x']\n",
        "      train_x, val_x, test_x = normalize_features(train_x, val_x, test_x)\n",
        "      np.savez_compressed('/content/drive/My Drive/Lab3_features/normalized/' + feature + '_norm', train_x=train_x, val_x=val_x, test_x=test_x)\n",
        "    else:\n",
        "      loaded = np.load('/content/drive/My Drive/Lab3_features/normalized/' + feature + '_norm.npz', allow_pickle=True)\n",
        "      train_x =  loaded['train_x']\n",
        "      val_x = loaded['val_x']\n",
        "      test_x = loaded['test_x']\n",
        "\n",
        "    return train_x, val_x, test_x\n",
        "\n",
        "# elif feature == 'mspec':\n",
        "#   if os.path.exists('/content/drive/My Drive/Lab3_features/normalized/mspec_norm.npz') == False:\n",
        "#     loaded = np.load('/content/drive/My Drive/Lab3_features/mspec.npz', allow_pickle=True)\n",
        "#     train_x =  loaded['mspec_train_x']\n",
        "#     val_x = loaded['mspec_val_x']\n",
        "#     test_x = loaded['mspec_test_x']\n",
        "#     train_x, val_x, test_x = normalize_features(train_x, val_x, test_x)\n",
        "#     np.savez_compressed('/content/drive/My Drive/Lab3_features/normalized/mspec_norm', mspec_train_x=train_x, mspec_val_x=val_x, mspec_test_x=test_x)\n",
        "#   else:\n",
        "#     loaded = np.load('/content/drive/My Drive/Lab3_features/normalized/mspec_norm.npz', allow_pickle=True)\n",
        "#     train_x =  loaded['mspec_train_x']\n",
        "#     val_x = loaded['mspec_val_x']\n",
        "#     test_x = loaded['mspec_test_x']\n",
        "\n",
        "# elif feature == 'dynlmfcc':\n",
        "#   if os.path.exists('/content/drive/My Drive/Lab3_features/normalized/dynlmfcc_norm.npz') == False:\n",
        "#     loaded = np.load('/content/drive/My Drive/Lab3_features/dynlmfcc.npz', allow_pickle=True)\n",
        "#     train_x =  loaded['dynlmfcc_train_x']\n",
        "#     val_x = loaded['dynlmfcc_val_x']\n",
        "#     test_x = loaded['dynlmfcc_test_x']\n",
        "#     train_x, val_x, test_x = normalize_features(train_x, val_x, test_x)\n",
        "#     np.savez_compressed('/content/drive/My Drive/Lab3_features/normalized/dynlmfcc_norm', dynlmfcc_train_x=train_x, dynlmfcc_val_x=val_x, dynlmfcc_test_x=test_x)\n",
        "#   else:\n",
        "#     loaded = np.load('/content/drive/My Drive/Lab3_features/normalized/dynlmfcc_norm.npz', allow_pickle=True)\n",
        "#     train_x =  loaded['dynlmfcc_train_x']\n",
        "#     val_x = loaded['dynlmfcc_val_x']\n",
        "#     test_x = loaded['dynlmfcc_test_x']\n",
        "\n",
        "# elif feature == 'dynmspec':\n",
        "#   if os.path.exists('/content/drive/My Drive/Lab3_features/normalized/dynmspec_norm.npz') == False:\n",
        "#     loaded = np.load('/content/drive/My Drive/Lab3_features/dynmspec.npz', allow_pickle=True)\n",
        "#     train_x =  loaded['dynmspec_train_x']\n",
        "#     val_x = loaded['dynmspec_val_x']\n",
        "#     test_x = loaded['dynmspec_test_x']\n",
        "#     train_x, val_x, test_x = normalize_features(train_x, val_x, test_x)\n",
        "#     np.savez_compressed('/content/drive/My Drive/Lab3_features/normalized/dynmspec_norm', dynmspec_train_x=train_x, dynmspec_val_x=val_x, dynmspec_test_x=test_x)\n",
        "#   else:\n",
        "#     loaded = np.load('/content/drive/My Drive/Lab3_features/normalized/dynmspec_norm.npz', allow_pickle=True)\n",
        "#     train_x =  loaded['dynmspec_train_x']\n",
        "#     val_x = loaded['dynmspec_val_x']\n",
        "#     test_x = loaded['dynmspec_test_x']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A46_vg1X1LsI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# train_y = np.load('/content/drive/My Drive/Lab3_features/train_y.npy')\n",
        "# val_y = np.load('/content/drive/My Drive/Lab3_features/val_y.npy')\n",
        "# test_y = np.load('/content/drive/My Drive/Lab3_features/test_y.npy')\n",
        "def normalizeTargets(train_y, val_y, test_y, stateList):\n",
        "  train_y_one_hot, val_y_one_hot, test_y_one_hot = normalize_targets(train_y, val_y, test_y, stateList)\n",
        "\n",
        "  return train_y_one_hot, val_y_one_hot, test_y_one_hot"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zydanardb6-m",
        "colab_type": "text"
      },
      "source": [
        "#5 Phoneme Recognition with Deep Neural Networks"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jjl-ePKUr2Bi",
        "colab_type": "text"
      },
      "source": [
        "Here are the minimum list of configurations to test, but you can test your favourite models if you manage to run the training in reasonable time. \n",
        "\n",
        "1. input: liftered MFCCs, one to four hidden layers of size 256, rectified linear units\n",
        "2. input: filterbank features, one to four hidden layers of size 256, rectified linear units\n",
        "3. same as 1. but with dynamic features as explained in Section 4.5\n",
        "4. same as 2. but with dynamic features as explained in Section 4.5\n",
        "\n",
        "Note the evolution of the loss function and the accuracy of the model for every epoch. What can you say comparing the results on the training and validation data? There are many other parameters that you can vary, if you have time to play with the models.\n",
        "For example:\n",
        "\n",
        "• different activation functions than ReLU\n",
        "\n",
        "• different number of hidden layers\n",
        "\n",
        "• different number of nodes per layer\n",
        "\n",
        "• different length of context input window\n",
        "\n",
        "• strategy to update learning rate and momentum\n",
        "\n",
        "• initialisation with DBNs instead of random\n",
        "\n",
        "• different normalisation of the feature vectors"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mv6Ki4JRcAn6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Activation\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint\n",
        "from sklearn.metrics import classification_report, confusion_matrix"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "biykBz3Pc27E",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def MLP(feature, num_layers, num_hidnodes, num_outputs, activation='relu', optimizer=Adam()):\n",
        "\n",
        "  if feature == 'lmfcc':\n",
        "      input_nodes = 13\n",
        "  elif feature == 'mspec':\n",
        "      input_nodes = 40\n",
        "  elif feature == 'dynlmfcc':\n",
        "      input_nodes = 91\n",
        "  elif feature == 'dynmspec':\n",
        "      input_nodes= 280\n",
        "\n",
        "\n",
        "  model = Sequential()\n",
        "  # A typical value for hidden nodes is 256, but you can experiment with this to see if convergence becomes faster or slower.\n",
        "  model.add(Dense(256, input_shape=(input_nodes,), activation=activation, dtype=\"float32\"))\n",
        "  model.add(Dense(256, activation=activation))\n",
        "  model.add(Dense(256, activation=activation))\n",
        "  model.add(Dense(256, activation=activation))\n",
        "\n",
        "  model.add(Dense(num_outputs))\n",
        "  model.add(Activation('softmax', name='posterior'))\n",
        "\n",
        "  model.compile(loss='categorical_crossentropy',optimizer=optimizer,metrics=['accuracy'])\n",
        "  model.summary()\n",
        "\n",
        "  return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eKMKuU4ofc12",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "def plot_history(history):\n",
        "\n",
        "    fig, axs = plt.subplots(2)\n",
        "    # create accuracy sublpot\n",
        "    axs[0].plot(history.history[\"accuracy\"], label=\"train accuracy\")\n",
        "    axs[0].plot(history.history[\"val_accuracy\"], label=\"test accuracy\")\n",
        "    axs[0].set_ylabel(\"Accuracy\")\n",
        "    axs[0].legend(loc=\"lower right\")\n",
        "    axs[0].set_title(\"Accuracy eval\")\n",
        "    # create error sublpot\n",
        "    axs[1].plot(history.history[\"loss\"], label=\"train error\")\n",
        "    axs[1].plot(history.history[\"val_loss\"], label=\"validation error\")\n",
        "    axs[1].set_ylabel(\"Error\")\n",
        "    axs[1].set_xlabel(\"Epoch\")\n",
        "    axs[1].legend(loc=\"upper right\")\n",
        "    axs[1].set_title(\"Error eval\")\n",
        "    plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M-fDyq6cdh7h",
        "colab_type": "text"
      },
      "source": [
        "## LMFCC features"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SwxmmvqheVg_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "feature = 'lmfcc'\n",
        "\n",
        "train_x, val_x, test_x, train_y, val_y, test_y = getFeatures(feature)\n",
        "train_x, val_x, test_x = normalizeFeatures(train_x, val_x, test_x)\n",
        "train_y_one_hot, val_y_one_hot, test_y_one_hot = normalizeTargets(train_y, val_y, test_y) \n",
        "\n",
        "model = MLP(feature=feature, num_layers=4, num_hidnodes=256, num_outputs=61, activation='relu', optimizer=Adam())\n",
        "\n",
        "filepath = \"/content/drive/My Drive/Lab3/weights.{epoch:02d}-{val_accuracy:.2f}.hdf5\"\n",
        "checkpoint = ModelCheckpoint(filepath, monitor='val_accuracy', verbose=1,\n",
        "                             save_best_only=True, mode='max')\n",
        "\n",
        "# model.fit(dynlmfcc_train_x, train_y_one_hot, epochs=10, batch_size=64,\n",
        "#           validation_data = (dynlmfcc_val_x, val_y_one_hot), callbacks=checkpoint)\n",
        "model.fit(train_x, train_y_one_hot, epochs=10, batch_size=256,\n",
        "          validation_data = (val_x, val_y_one_hot), callbacks=checkpoint)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qvnAMWYEfom-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "def plot_history(history):\n",
        "\n",
        "    fig, axs = plt.subplots(2)\n",
        "    # create accuracy sublpot\n",
        "    axs[0].plot(history.history[\"accuracy\"], label=\"train accuracy\")\n",
        "    axs[0].plot(history.history[\"val_accuracy\"], label=\"test accuracy\")\n",
        "    axs[0].set_ylabel(\"Accuracy\")\n",
        "    axs[0].legend(loc=\"lower right\")\n",
        "    axs[0].set_title(\"Accuracy eval\")\n",
        "    # create error sublpot\n",
        "    axs[1].plot(history.history[\"loss\"], label=\"train error\")\n",
        "    axs[1].plot(history.history[\"val_loss\"], label=\"validation error\")\n",
        "    axs[1].set_ylabel(\"Error\")\n",
        "    axs[1].set_xlabel(\"Epoch\")\n",
        "    axs[1].legend(loc=\"upper right\")\n",
        "    axs[1].set_title(\"Error eval\")\n",
        "    plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HD305jQyfLaK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# print(\"Evaluating model on test data...\")\n",
        "# results = model.evaluate(test_x, test_y_one_hot)\n",
        "# print(\"Test loss:\", results[0])\n",
        "# print(\"Test acc:\", results[1])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7STc2FfUHiiw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# test_y_pred = np.argmax(model.predict(test_x), axis=1)\n",
        "\n",
        "# print(\"Confusion matrix:\")\n",
        "# print(confusion_matrix(test_y_one_hot, test_y_pred))\n",
        "# # print(\"Classification reprot:\")\n",
        "# # print(classification_report(test_y, test_y_pred, digits=61))"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}